{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04b73f47",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-17T11:57:10.369594Z",
     "iopub.status.busy": "2026-01-17T11:57:10.369047Z",
     "iopub.status.idle": "2026-01-17T11:57:10.372806Z",
     "shell.execute_reply": "2026-01-17T11:57:10.372266Z"
    },
    "papermill": {
     "duration": 0.008605,
     "end_time": "2026-01-17T11:57:10.374152",
     "exception": false,
     "start_time": "2026-01-17T11:57:10.365547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# SRC=\"/kaggle/input/verse-19-3d-images/dataset-verse19validation\"\n",
    "# DST=\"/kaggle/working/verse19/dataset-verse19validation\"\n",
    "\n",
    "# mkdir -p \"$DST/rawdata\" \"$DST/derivatives\"\n",
    "\n",
    "# # Get first 5 folders and copy them\n",
    "# for sub in $(ls -1 \"$SRC/rawdata\" | head -n 5); do\n",
    "#     cp -r \"$SRC/rawdata/$sub\" \"$DST/rawdata/\"\n",
    "#     cp -r \"$SRC/derivatives/$sub\" \"$DST/derivatives/\"\n",
    "#     echo \"Copied $sub\"\n",
    "# done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d81ae317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T11:57:10.378849Z",
     "iopub.status.busy": "2026-01-17T11:57:10.378650Z",
     "iopub.status.idle": "2026-01-17T11:57:10.381803Z",
     "shell.execute_reply": "2026-01-17T11:57:10.381244Z"
    },
    "papermill": {
     "duration": 0.007062,
     "end_time": "2026-01-17T11:57:10.383169",
     "exception": false,
     "start_time": "2026-01-17T11:57:10.376107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# SRC=\"/kaggle/input/verse-19-3d-images/dataset-verse19training\"\n",
    "# DST=\"/kaggle/working/verse19/dataset-verse19training\"\n",
    "\n",
    "# mkdir -p \"$DST/rawdata\" \"$DST/derivatives\"\n",
    "\n",
    "# # Get first 5 folders and copy them\n",
    "# for sub in $(ls -1 \"$SRC/rawdata\" | head -n 5); do\n",
    "#     cp -r \"$SRC/rawdata/$sub\" \"$DST/rawdata/\"\n",
    "#     cp -r \"$SRC/derivatives/$sub\" \"$DST/derivatives/\"\n",
    "#     echo \"Copied $sub\"\n",
    "# done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "533c3513",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T11:57:10.388144Z",
     "iopub.status.busy": "2026-01-17T11:57:10.387698Z",
     "iopub.status.idle": "2026-01-17T11:57:10.390806Z",
     "shell.execute_reply": "2026-01-17T11:57:10.390061Z"
    },
    "papermill": {
     "duration": 0.007168,
     "end_time": "2026-01-17T11:57:10.392266",
     "exception": false,
     "start_time": "2026-01-17T11:57:10.385098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# SRC=\"/kaggle/input/verse-19-3d-images/dataset-verse19test\"\n",
    "# DST=\"/kaggle/working/verse19/dataset-verse19test\"\n",
    "\n",
    "# mkdir -p \"$DST/rawdata\" \"$DST/derivatives\"\n",
    "\n",
    "# # Get first 5 folders and copy them\n",
    "# for sub in $(ls -1 \"$SRC/rawdata\" | head -n 5); do\n",
    "#     cp -r \"$SRC/rawdata/$sub\" \"$DST/rawdata/\"\n",
    "#     cp -r \"$SRC/derivatives/$sub\" \"$DST/derivatives/\"\n",
    "#     echo \"Copied $sub\"\n",
    "# done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e792c0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T11:57:10.396851Z",
     "iopub.status.busy": "2026-01-17T11:57:10.396446Z",
     "iopub.status.idle": "2026-01-17T11:57:11.109940Z",
     "shell.execute_reply": "2026-01-17T11:57:11.109009Z"
    },
    "papermill": {
     "duration": 0.717722,
     "end_time": "2026-01-17T11:57:11.111708",
     "exception": false,
     "start_time": "2026-01-17T11:57:10.393986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SpineSegmentation_HealthiVert'...\r\n",
      "remote: Enumerating objects: 84, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (84/84), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (64/64), done.\u001b[K\r\n",
      "remote: Total 84 (delta 29), reused 74 (delta 19), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (84/84), 77.30 KiB | 2.86 MiB/s, done.\r\n",
      "Resolving deltas: 100% (29/29), done.\r\n"
     ]
    }
   ],
   "source": [
    "# !rm -rf /kaggle/working/SpineSegmentation_HealthiVert\n",
    "!git clone https://github.com/ahmed-226/SpineSegmentation_HealthiVert.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be475f9",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-17T11:57:11.118116Z",
     "iopub.status.busy": "2026-01-17T11:57:11.117490Z",
     "iopub.status.idle": "2026-01-17T11:57:16.613103Z",
     "shell.execute_reply": "2026-01-17T11:57:16.612098Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 5.501008,
     "end_time": "2026-01-17T11:57:16.615123",
     "exception": false,
     "start_time": "2026-01-17T11:57:11.114115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (2.8.0+cu126)\r\n",
      "Requirement already satisfied: torchvision>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (0.23.0+cu126)\r\n",
      "Requirement already satisfied: nibabel>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (5.3.2)\r\n",
      "Requirement already satisfied: SimpleITK>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (2.5.3)\r\n",
      "Collecting torchio>=0.19.0 (from -r requirements.txt (line 11))\r\n",
      "  Downloading torchio-0.21.1-py3-none-any.whl.metadata (52 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (2.0.2)\r\n",
      "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (1.15.3)\r\n",
      "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (2.2.2)\r\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 19)) (3.5)\r\n",
      "Requirement already satisfied: tensorboard>=2.12.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 22)) (2.19.0)\r\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 23)) (4.67.1)\r\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 26)) (3.10.0)\r\n",
      "Requirement already satisfied: pytest>=7.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 29)) (8.4.2)\r\n",
      "Requirement already satisfied: black>=23.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 30)) (25.12.0)\r\n",
      "Collecting flake8>=6.0.0 (from -r requirements.txt (line 31))\r\n",
      "  Downloading flake8-7.3.0-py2.py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (3.20.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (4.15.0)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (75.2.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (1.13.3)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (2025.10.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.6.80)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (9.10.2.21)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.6.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (11.3.0.4)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (10.3.7.77)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (11.7.1.2)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.5.4.2)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (0.7.1)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (2.27.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.6.85)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (1.11.1.6)\r\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (3.4.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.15.0->-r requirements.txt (line 6)) (11.3.0)\r\n",
      "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from nibabel>=5.0.0->-r requirements.txt (line 9)) (26.0rc2)\r\n",
      "Requirement already satisfied: deprecated>=1.2 in /usr/local/lib/python3.12/dist-packages (from torchio>=0.19.0->-r requirements.txt (line 11)) (1.3.1)\r\n",
      "Requirement already satisfied: einops>=0.3 in /usr/local/lib/python3.12/dist-packages (from torchio>=0.19.0->-r requirements.txt (line 11)) (0.8.1)\r\n",
      "Requirement already satisfied: humanize>=0.1 in /usr/local/lib/python3.12/dist-packages (from torchio>=0.19.0->-r requirements.txt (line 11)) (4.14.0)\r\n",
      "Requirement already satisfied: rich>=10 in /usr/local/lib/python3.12/dist-packages (from torchio>=0.19.0->-r requirements.txt (line 11)) (14.2.0)\r\n",
      "Requirement already satisfied: typer>=0.1 in /usr/local/lib/python3.12/dist-packages (from torchio>=0.19.0->-r requirements.txt (line 11)) (0.20.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 16)) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 16)) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 16)) (2025.2)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.12.0->-r requirements.txt (line 22)) (1.4.0)\r\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.12.0->-r requirements.txt (line 22)) (1.75.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.12.0->-r requirements.txt (line 22)) (3.9)\r\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.12.0->-r requirements.txt (line 22)) (5.29.5)\r\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.12.0->-r requirements.txt (line 22)) (1.17.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.12.0->-r requirements.txt (line 22)) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.12.0->-r requirements.txt (line 22)) (3.1.3)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 26)) (1.3.3)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 26)) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 26)) (4.60.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 26)) (1.4.9)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 26)) (3.2.5)\r\n",
      "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest>=7.3.0->-r requirements.txt (line 29)) (2.3.0)\r\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest>=7.3.0->-r requirements.txt (line 29)) (1.6.0)\r\n",
      "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest>=7.3.0->-r requirements.txt (line 29)) (2.19.2)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from black>=23.0.0->-r requirements.txt (line 30)) (8.3.1)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from black>=23.0.0->-r requirements.txt (line 30)) (1.1.0)\r\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from black>=23.0.0->-r requirements.txt (line 30)) (1.0.3)\r\n",
      "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.12/dist-packages (from black>=23.0.0->-r requirements.txt (line 30)) (4.5.1)\r\n",
      "Requirement already satisfied: pytokens>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from black>=23.0.0->-r requirements.txt (line 30)) (0.3.0)\r\n",
      "Collecting mccabe<0.8.0,>=0.7.0 (from flake8>=6.0.0->-r requirements.txt (line 31))\r\n",
      "  Downloading mccabe-0.7.0-py2.py3-none-any.whl.metadata (5.0 kB)\r\n",
      "Collecting pycodestyle<2.15.0,>=2.14.0 (from flake8>=6.0.0->-r requirements.txt (line 31))\r\n",
      "  Downloading pycodestyle-2.14.0-py2.py3-none-any.whl.metadata (4.5 kB)\r\n",
      "Collecting pyflakes<3.5.0,>=3.4.0 (from flake8>=6.0.0->-r requirements.txt (line 31))\r\n",
      "  Downloading pyflakes-3.4.0-py2.py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Requirement already satisfied: wrapt<3,>=1.10 in /usr/local/lib/python3.12/dist-packages (from deprecated>=1.2->torchio>=0.19.0->-r requirements.txt (line 11)) (2.0.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10->torchio>=0.19.0->-r requirements.txt (line 11)) (4.0.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->-r requirements.txt (line 5)) (1.3.0)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.1->torchio>=0.19.0->-r requirements.txt (line 11)) (1.5.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.12.0->-r requirements.txt (line 22)) (3.0.3)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10->torchio>=0.19.0->-r requirements.txt (line 11)) (0.1.2)\r\n",
      "Downloading torchio-0.21.1-py3-none-any.whl (194 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.3/194.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading flake8-7.3.0-py2.py3-none-any.whl (57 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\r\n",
      "Downloading pycodestyle-2.14.0-py2.py3-none-any.whl (31 kB)\r\n",
      "Downloading pyflakes-3.4.0-py2.py3-none-any.whl (63 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pyflakes, pycodestyle, mccabe, flake8, torchio\r\n",
      "Successfully installed flake8-7.3.0 mccabe-0.7.0 pycodestyle-2.14.0 pyflakes-3.4.0 torchio-0.21.1\r\n"
     ]
    }
   ],
   "source": [
    "!cd /kaggle/working/SpineSegmentation_HealthiVert/ && ! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef37c4f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T11:57:16.623976Z",
     "iopub.status.busy": "2026-01-17T11:57:16.623250Z",
     "iopub.status.idle": "2026-01-17T11:57:18.314303Z",
     "shell.execute_reply": "2026-01-17T11:57:18.313285Z"
    },
    "papermill": {
     "duration": 1.697496,
     "end_time": "2026-01-17T11:57:18.316184",
     "exception": false,
     "start_time": "2026-01-17T11:57:16.618688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning for subjects in /kaggle/input/verse-19-3d-images...\r\n",
      "Warning: No CT image found for sub-verse400\r\n",
      "Warning: No CT image found for sub-verse108\r\n",
      "Warning: No CT image found for sub-verse236\r\n",
      "Warning: No CT image found for sub-verse076\r\n",
      "Warning: No CT image found for sub-verse005\r\n",
      "Found 136 subjects.\r\n",
      "Split distribution: {'validation': 36, 'test': 35, 'training': 65}\r\n",
      "Subjects with landmarks: 136\r\n",
      "Subjects with segmentation masks: 135\r\n",
      "\r\n",
      "Final splits:\r\n",
      "  Training: 65\r\n",
      "  Validation: 36\r\n",
      "  Test: 35\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/prepare_data.py\", line 252, in <module>\r\n",
      "    main()\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/prepare_data.py\", line 218, in main\r\n",
      "    with open(train_file, 'w') as f:\r\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\r\n",
      "OSError: [Errno 30] Read-only file system: '/kaggle/input/verse-19-3d-images/train.txt'\r\n"
     ]
    }
   ],
   "source": [
    "! cd SpineSegmentation_HealthiVert/ && ! python prepare_data.py --data_dir /kaggle/input/verse-19-3d-images --output_dir ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e8193fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T11:57:18.325010Z",
     "iopub.status.busy": "2026-01-17T11:57:18.324702Z",
     "iopub.status.idle": "2026-01-17T11:57:18.328074Z",
     "shell.execute_reply": "2026-01-17T11:57:18.327505Z"
    },
    "papermill": {
     "duration": 0.009769,
     "end_time": "2026-01-17T11:57:18.329526",
     "exception": false,
     "start_time": "2026-01-17T11:57:18.319757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -rf verse19/output\n",
    "# !mkdir -p verse19/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f2b48a",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-01-17T11:57:18.337679Z",
     "iopub.status.busy": "2026-01-17T11:57:18.337425Z",
     "iopub.status.idle": "2026-01-17T12:03:44.798398Z",
     "shell.execute_reply": "2026-01-17T12:03:44.797605Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 386.467059,
     "end_time": "2026-01-17T12:03:44.800236",
     "exception": false,
     "start_time": "2026-01-17T11:57:18.333177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-17 11:57:26.430577: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1768651046.585011      68 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1768651046.629051      68 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "W0000 00:00:1768651046.980763      68 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1768651046.980828      68 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1768651046.980835      68 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1768651046.980842      68 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "2026-01-17 11:57:40,243 - INFO - ======================================================================\r\n",
      "2026-01-17 11:57:40,243 - INFO - VerSe2019 Pipeline - K-Fold Cross-Validation Training\r\n",
      "2026-01-17 11:57:40,243 - INFO - ======================================================================\r\n",
      "2026-01-17 11:57:40,243 - INFO - Data directory: /kaggle/input/verse-19-3d-images\r\n",
      "2026-01-17 11:57:40,244 - INFO - Output directory: /kaggle/working/output\r\n",
      "2026-01-17 11:57:40,244 - INFO - Stage: all\r\n",
      "2026-01-17 11:57:40,244 - INFO - Number of folds: 5\r\n",
      "2026-01-17 11:57:40,244 - INFO - Specific fold: All\r\n",
      "2026-01-17 11:57:40,273 - INFO - Multi-GPU mode: Using 2 GPUs: ['Tesla T4', 'Tesla T4']\r\n",
      "2026-01-17 11:57:40,273 - INFO - Batch size: 2\r\n",
      "2026-01-17 11:57:40,274 - INFO - Learning rate: 0.0001\r\n",
      "2026-01-17 11:57:40,274 - INFO - Max iterations: 10\r\n",
      "2026-01-17 11:57:40,274 - INFO - ======================================================================\r\n",
      "2026-01-17 11:57:40,276 - INFO - No train.txt or val.txt found or they were empty. Scanning for subjects...\r\n",
      "2026-01-17 11:57:40,659 - INFO - Found 37 subjects in /kaggle/input/verse-19-3d-images/dataset-verse19validation/rawdata\r\n",
      "2026-01-17 11:57:40,660 - INFO - Found 37 subjects in /kaggle/input/verse-19-3d-images/dataset-verse19test/rawdata\r\n",
      "2026-01-17 11:57:40,661 - INFO - Found 67 subjects in /kaggle/input/verse-19-3d-images/dataset-verse19training/rawdata\r\n",
      "2026-01-17 11:57:40,661 - INFO - Total subjects for cross-validation: 141\r\n",
      "2026-01-17 11:57:40,661 - INFO - Fold summary: {'n_folds': 5, 'train_sizes': [112, 113, 113, 113, 113], 'val_sizes': [29, 28, 28, 28, 28], 'avg_train_size': np.float64(112.8), 'avg_val_size': np.float64(28.2), 'total_samples': 141}\r\n",
      "Saved 5 fold splits to /kaggle/working/output/fold_splits\r\n",
      "2026-01-17 11:57:40,662 - INFO - Loading landmarks...\r\n",
      "[load_all_verse_landmarks] Loaded: 123/141 subjects, Missing: 18, Total valid landmarks: 1241\r\n",
      "2026-01-17 11:57:41,331 - INFO - Loaded landmarks for 141 subjects\r\n",
      "2026-01-17 11:57:41,331 - INFO - \r\n",
      "2026-01-17 11:57:41,332 - INFO - ======================================================================\r\n",
      "2026-01-17 11:57:41,332 - INFO - FOLD 1/5\r\n",
      "2026-01-17 11:57:41,332 - INFO -   Train: 112 samples, Val: 29 samples\r\n",
      "2026-01-17 11:57:41,332 - INFO - ======================================================================\r\n",
      "2026-01-17 11:57:41,332 - INFO -   Training Stage 1 (Fold 0)...\r\n",
      "2026-01-17 11:57:41,664 - INFO - Multi-GPU training enabled: Using 2 GPUs [0, 1]\r\n",
      "2026-01-17 11:57:41,858 - INFO - Model wrapped with DataParallel on GPUs: [0, 1]\r\n",
      "2026-01-17 11:57:41,858 - INFO - Using provided model with 21,191,937 parameters\r\n",
      "2026-01-17 11:57:46,541 - INFO - Train samples: 112, Val samples: 29\r\n",
      "2026-01-17 11:57:46,542 - INFO - TensorBoard logs: /kaggle/working/output/stage1/fold_0/logs/fold_0\r\n",
      "2026-01-17 11:57:46,542 - INFO - Starting spine localization training...\r\n",
      "2026-01-17 11:57:55,785 - INFO - Iter 1/10 | Loss: 174635.921875 | LR: 7.94e-05 | Speed: 0.11 it/s | ETA: 1.4min\r\n",
      "2026-01-17 11:58:13,398 - INFO - Iter 10/10 | Loss: 36827.406250 | LR: 1.00e-05 | Speed: 0.39 it/s | ETA: 0.0min\r\n",
      "2026-01-17 11:58:13,747 - INFO - Saved checkpoint: /kaggle/working/output/stage1/fold_0/checkpoints/fold_0/final_model.pth\r\n",
      "2026-01-17 11:58:13,747 - INFO - Training completed!\r\n",
      "2026-01-17 11:58:14,250 - INFO -   Stage 1 checkpoint: /kaggle/working/output/stage1/fold_0/checkpoints/fold_0/final_model.pth\r\n",
      "2026-01-17 11:58:14,250 - INFO -   Training Stage 2 (Fold 0)...\r\n",
      "[DEBUG] Elastic deformation: num_control_points=5, max_displacement=5.0\r\n",
      "2026-01-17 11:58:14,912 - INFO - Multi-GPU training enabled: Using 2 GPUs [0, 1]\r\n",
      "2026-01-17 11:58:14,969 - INFO - Model wrapped with DataParallel on GPUs: [0, 1]\r\n",
      "2026-01-17 11:58:14,970 - INFO - Using provided model with 50,598,770 parameters\r\n",
      "2026-01-17 11:58:14,970 - INFO - Train samples: 112, Val samples: 29\r\n",
      "2026-01-17 11:58:14,971 - INFO - TensorBoard logs: /kaggle/working/output/stage2/fold_0/logs/fold_0\r\n",
      "2026-01-17 11:58:14,971 - INFO - Starting vertebrae localization training...\r\n",
      "2026-01-17 11:58:29,045 - INFO - Iter 1/10 | Loss: 784460.875000 | Sigma: [4.00, 4.00] | Speed: 0.07 it/s | ETA: 2.1min\r\n",
      "2026-01-17 11:59:15,982 - INFO - Iter 10/10 | Loss: 353020.312500 | Sigma: [4.00, 4.00] | Speed: 0.18 it/s | ETA: 0.0min\r\n",
      "2026-01-17 11:59:16,769 - INFO - Saved checkpoint: /kaggle/working/output/stage2/fold_0/checkpoints/fold_0/final_model.pth\r\n",
      "2026-01-17 11:59:16,769 - INFO - Training completed!\r\n",
      "2026-01-17 11:59:16,825 - INFO -   Stage 2 checkpoint: /kaggle/working/output/stage2/fold_0/checkpoints/fold_0/final_model.pth\r\n",
      "2026-01-17 11:59:16,825 - INFO -   Training Stage 3 (Fold 0)...\r\n",
      "[VertebraeSegmentationDataset] Warning: 11 IDs have no valid landmarks: ['sub-verse414', 'sub-verse401', 'sub-verse404', 'sub-verse411', 'sub-verse409']...\r\n",
      "[VertebraeSegmentationDataset] Warning: 7 IDs have no valid landmarks: ['sub-verse406', 'sub-verse416', 'sub-verse410', 'sub-verse405', 'sub-verse403']...\r\n",
      "2026-01-17 11:59:17,102 - INFO -   Stage 3 datasets - Train: 1015 vertebra samples, Val: 226 vertebra samples\r\n",
      "2026-01-17 11:59:17,103 - INFO - Multi-GPU training enabled: Using 2 GPUs [0, 1]\r\n",
      "2026-01-17 11:59:17,131 - INFO - Model wrapped with DataParallel on GPUs: [0, 1]\r\n",
      "2026-01-17 11:59:17,132 - INFO - Using provided model with 21,193,627 parameters\r\n",
      "2026-01-17 11:59:17,133 - INFO - Train samples: 1015, Val samples: 226\r\n",
      "2026-01-17 11:59:17,134 - INFO - TensorBoard logs: /kaggle/working/output/stage3/fold_0/logs/fold_0\r\n",
      "2026-01-17 11:59:17,134 - INFO - Starting vertebrae segmentation training...\r\n",
      "2026-01-17 11:59:22,197 - INFO - Iter 1/10 | Loss: 3.454727 | Speed: 0.30 it/s | ETA: 0.5min\r\n",
      "2026-01-17 11:59:33,891 - ERROR - Error in fold 0: Caught FileNotFoundError in DataLoader worker process 1.\r\n",
      "Original Traceback (most recent call last):\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\r\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\r\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n",
      "            ~~~~~~~~~~~~^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/data/dataset.py\", line 1093, in __getitem__\r\n",
      "    image_path, label_path = self._get_paths(image_id)\r\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/data/dataset.py\", line 1083, in _get_paths\r\n",
      "    raise FileNotFoundError(f\"Image not found for ID: {image_id}\")\r\n",
      "FileNotFoundError: Image not found for ID: sub-verse236\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/train_kfold.py\", line 542, in main\r\n",
      "    ckpt3 = train_fold_stage3(\r\n",
      "            ^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/train_kfold.py\", line 291, in train_fold_stage3\r\n",
      "    trainer.train()\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/training/trainer.py\", line 954, in train\r\n",
      "    batch = next(train_iter)\r\n",
      "            ^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 734, in __next__\r\n",
      "    data = self._next_data()\r\n",
      "           ^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1489, in _next_data\r\n",
      "    return self._process_data(data, worker_id)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1551, in _process_data\r\n",
      "    data.reraise()\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/_utils.py\", line 769, in reraise\r\n",
      "    raise exception\r\n",
      "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 1.\r\n",
      "Original Traceback (most recent call last):\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\r\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\r\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n",
      "            ~~~~~~~~~~~~^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/data/dataset.py\", line 1093, in __getitem__\r\n",
      "    image_path, label_path = self._get_paths(image_id)\r\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/data/dataset.py\", line 1083, in _get_paths\r\n",
      "    raise FileNotFoundError(f\"Image not found for ID: {image_id}\")\r\n",
      "FileNotFoundError: Image not found for ID: sub-verse236\r\n",
      "\r\n",
      "2026-01-17 11:59:33,896 - INFO - \r\n",
      "2026-01-17 11:59:33,896 - INFO - ======================================================================\r\n",
      "2026-01-17 11:59:33,896 - INFO - FOLD 2/5\r\n",
      "2026-01-17 11:59:33,896 - INFO -   Train: 113 samples, Val: 28 samples\r\n",
      "2026-01-17 11:59:33,896 - INFO - ======================================================================\r\n",
      "2026-01-17 11:59:33,897 - INFO -   Training Stage 1 (Fold 1)...\r\n",
      "2026-01-17 11:59:34,250 - INFO - Multi-GPU training enabled: Using 2 GPUs [0, 1]\r\n",
      "2026-01-17 11:59:36,269 - INFO - Model wrapped with DataParallel on GPUs: [0, 1]\r\n",
      "2026-01-17 11:59:36,269 - INFO - Using provided model with 21,191,937 parameters\r\n",
      "2026-01-17 11:59:36,269 - INFO - Train samples: 113, Val samples: 28\r\n",
      "2026-01-17 11:59:36,271 - INFO - TensorBoard logs: /kaggle/working/output/stage1/fold_1/logs/fold_1\r\n",
      "2026-01-17 11:59:36,271 - INFO - Starting spine localization training...\r\n",
      "2026-01-17 11:59:39,328 - INFO - Iter 1/10 | Loss: 93983.843750 | LR: 7.94e-05 | Speed: 0.52 it/s | ETA: 0.3min\r\n",
      "2026-01-17 11:59:55,797 - ERROR - Error in fold 1: Caught FileNotFoundError in DataLoader worker process 1.\r\n",
      "Original Traceback (most recent call last):\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\r\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\r\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n",
      "            ~~~~~~~~~~~~^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/data/dataset.py\", line 529, in __getitem__\r\n",
      "    image_path = self._get_image_path(image_id)\r\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/data/dataset.py\", line 523, in _get_image_path\r\n",
      "    raise FileNotFoundError(f\"Image not found for ID: {image_id}\")\r\n",
      "FileNotFoundError: Image not found for ID: sub-verse108\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/train_kfold.py\", line 526, in main\r\n",
      "    ckpt1 = train_fold_stage1(\r\n",
      "            ^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/train_kfold.py\", line 152, in train_fold_stage1\r\n",
      "    trainer.train()\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/training/trainer.py\", line 363, in train\r\n",
      "    batch = next(train_iter)\r\n",
      "            ^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 734, in __next__\r\n",
      "    data = self._next_data()\r\n",
      "           ^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1516, in _next_data\r\n",
      "    return self._process_data(data, worker_id)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1551, in _process_data\r\n",
      "    data.reraise()\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/_utils.py\", line 769, in reraise\r\n",
      "    raise exception\r\n",
      "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 1.\r\n",
      "Original Traceback (most recent call last):\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\r\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\r\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n",
      "            ~~~~~~~~~~~~^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/data/dataset.py\", line 529, in __getitem__\r\n",
      "    image_path = self._get_image_path(image_id)\r\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/data/dataset.py\", line 523, in _get_image_path\r\n",
      "    raise FileNotFoundError(f\"Image not found for ID: {image_id}\")\r\n",
      "FileNotFoundError: Image not found for ID: sub-verse108\r\n",
      "\r\n",
      "2026-01-17 11:59:55,800 - INFO - \r\n",
      "2026-01-17 11:59:55,800 - INFO - ======================================================================\r\n",
      "2026-01-17 11:59:55,800 - INFO - FOLD 3/5\r\n",
      "2026-01-17 11:59:55,800 - INFO -   Train: 113 samples, Val: 28 samples\r\n",
      "2026-01-17 11:59:55,800 - INFO - ======================================================================\r\n",
      "2026-01-17 11:59:55,801 - INFO -   Training Stage 1 (Fold 2)...\r\n",
      "2026-01-17 11:59:57,968 - INFO - Multi-GPU training enabled: Using 2 GPUs [0, 1]\r\n",
      "2026-01-17 11:59:57,991 - INFO - Model wrapped with DataParallel on GPUs: [0, 1]\r\n",
      "2026-01-17 11:59:57,991 - INFO - Using provided model with 21,191,937 parameters\r\n",
      "2026-01-17 11:59:57,992 - INFO - Train samples: 113, Val samples: 28\r\n",
      "2026-01-17 11:59:57,993 - INFO - TensorBoard logs: /kaggle/working/output/stage1/fold_2/logs/fold_2\r\n",
      "2026-01-17 11:59:57,993 - INFO - Starting spine localization training...\r\n",
      "2026-01-17 12:00:02,056 - INFO - Iter 1/10 | Loss: 218782.343750 | LR: 7.94e-05 | Speed: 0.34 it/s | ETA: 0.4min\r\n",
      "2026-01-17 12:00:26,156 - INFO - Iter 10/10 | Loss: 66003.281250 | LR: 1.00e-05 | Speed: 0.37 it/s | ETA: 0.0min\r\n",
      "2026-01-17 12:00:26,533 - INFO - Saved checkpoint: /kaggle/working/output/stage1/fold_2/checkpoints/fold_2/final_model.pth\r\n",
      "2026-01-17 12:00:26,534 - INFO - Training completed!\r\n",
      "2026-01-17 12:00:30,244 - INFO -   Stage 1 checkpoint: /kaggle/working/output/stage1/fold_2/checkpoints/fold_2/final_model.pth\r\n",
      "2026-01-17 12:00:30,244 - INFO -   Training Stage 2 (Fold 2)...\r\n",
      "[DEBUG] Elastic deformation: num_control_points=5, max_displacement=5.0\r\n",
      "2026-01-17 12:00:30,864 - INFO - Multi-GPU training enabled: Using 2 GPUs [0, 1]\r\n",
      "2026-01-17 12:00:30,920 - INFO - Model wrapped with DataParallel on GPUs: [0, 1]\r\n",
      "2026-01-17 12:00:30,920 - INFO - Using provided model with 50,598,770 parameters\r\n",
      "2026-01-17 12:00:30,921 - INFO - Train samples: 113, Val samples: 28\r\n",
      "2026-01-17 12:00:30,922 - INFO - TensorBoard logs: /kaggle/working/output/stage2/fold_2/logs/fold_2\r\n",
      "2026-01-17 12:00:30,922 - INFO - Starting vertebrae localization training...\r\n",
      "2026-01-17 12:00:45,577 - INFO - Iter 1/10 | Loss: 667466.500000 | Sigma: [4.00, 4.00] | Speed: 0.11 it/s | ETA: 1.3min\r\n",
      "2026-01-17 12:01:38,349 - INFO - Iter 10/10 | Loss: 319931.625000 | Sigma: [4.00, 4.00] | Speed: 0.16 it/s | ETA: 0.0min\r\n",
      "2026-01-17 12:01:39,188 - INFO - Saved checkpoint: /kaggle/working/output/stage2/fold_2/checkpoints/fold_2/final_model.pth\r\n",
      "2026-01-17 12:01:39,188 - INFO - Training completed!\r\n",
      "2026-01-17 12:01:39,261 - INFO -   Stage 2 checkpoint: /kaggle/working/output/stage2/fold_2/checkpoints/fold_2/final_model.pth\r\n",
      "2026-01-17 12:01:39,262 - INFO -   Training Stage 3 (Fold 2)...\r\n",
      "[VertebraeSegmentationDataset] Warning: 13 IDs have no valid landmarks: ['sub-verse406', 'sub-verse416', 'sub-verse410', 'sub-verse405', 'sub-verse403']...\r\n",
      "[VertebraeSegmentationDataset] Warning: 5 IDs have no valid landmarks: ['sub-verse404', 'sub-verse411', 'sub-verse409', 'sub-verse408', 'sub-verse415']\r\n",
      "2026-01-17 12:01:39,525 - INFO -   Stage 3 datasets - Train: 1012 vertebra samples, Val: 229 vertebra samples\r\n",
      "2026-01-17 12:01:39,525 - INFO - Multi-GPU training enabled: Using 2 GPUs [0, 1]\r\n",
      "2026-01-17 12:01:39,548 - INFO - Model wrapped with DataParallel on GPUs: [0, 1]\r\n",
      "2026-01-17 12:01:39,548 - INFO - Using provided model with 21,193,627 parameters\r\n",
      "2026-01-17 12:01:39,548 - INFO - Train samples: 1012, Val samples: 229\r\n",
      "2026-01-17 12:01:39,549 - INFO - TensorBoard logs: /kaggle/working/output/stage3/fold_2/logs/fold_2\r\n",
      "2026-01-17 12:01:39,549 - INFO - Starting vertebrae segmentation training...\r\n",
      "2026-01-17 12:01:39,828 - ERROR - Error in fold 2: Caught FileNotFoundError in DataLoader worker process 0.\r\n",
      "Original Traceback (most recent call last):\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\r\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\r\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n",
      "            ~~~~~~~~~~~~^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/data/dataset.py\", line 1093, in __getitem__\r\n",
      "    image_path, label_path = self._get_paths(image_id)\r\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/data/dataset.py\", line 1085, in _get_paths\r\n",
      "    raise FileNotFoundError(f\"Label not found for ID: {image_id}\")\r\n",
      "FileNotFoundError: Label not found for ID: sub-verse012\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/train_kfold.py\", line 542, in main\r\n",
      "    ckpt3 = train_fold_stage3(\r\n",
      "            ^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/train_kfold.py\", line 291, in train_fold_stage3\r\n",
      "    trainer.train()\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/training/trainer.py\", line 954, in train\r\n",
      "    batch = next(train_iter)\r\n",
      "            ^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 734, in __next__\r\n",
      "    data = self._next_data()\r\n",
      "           ^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1516, in _next_data\r\n",
      "    return self._process_data(data, worker_id)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1551, in _process_data\r\n",
      "    data.reraise()\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/_utils.py\", line 769, in reraise\r\n",
      "    raise exception\r\n",
      "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.\r\n",
      "Original Traceback (most recent call last):\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\r\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\r\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n",
      "            ~~~~~~~~~~~~^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/data/dataset.py\", line 1093, in __getitem__\r\n",
      "    image_path, label_path = self._get_paths(image_id)\r\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/data/dataset.py\", line 1085, in _get_paths\r\n",
      "    raise FileNotFoundError(f\"Label not found for ID: {image_id}\")\r\n",
      "FileNotFoundError: Label not found for ID: sub-verse012\r\n",
      "\r\n",
      "2026-01-17 12:01:39,831 - INFO - \r\n",
      "2026-01-17 12:01:39,831 - INFO - ======================================================================\r\n",
      "2026-01-17 12:01:39,831 - INFO - FOLD 4/5\r\n",
      "2026-01-17 12:01:39,831 - INFO -   Train: 113 samples, Val: 28 samples\r\n",
      "2026-01-17 12:01:39,831 - INFO - ======================================================================\r\n",
      "2026-01-17 12:01:39,831 - INFO -   Training Stage 1 (Fold 3)...\r\n",
      "2026-01-17 12:01:41,347 - INFO - Multi-GPU training enabled: Using 2 GPUs [0, 1]\r\n",
      "2026-01-17 12:01:41,370 - INFO - Model wrapped with DataParallel on GPUs: [0, 1]\r\n",
      "2026-01-17 12:01:41,370 - INFO - Using provided model with 21,191,937 parameters\r\n",
      "2026-01-17 12:01:41,371 - INFO - Train samples: 113, Val samples: 28\r\n",
      "2026-01-17 12:01:41,372 - INFO - TensorBoard logs: /kaggle/working/output/stage1/fold_3/logs/fold_3\r\n",
      "2026-01-17 12:01:41,372 - INFO - Starting spine localization training...\r\n",
      "2026-01-17 12:01:43,153 - INFO - Iter 1/10 | Loss: 74542.625000 | LR: 7.94e-05 | Speed: 1.52 it/s | ETA: 0.1min\r\n",
      "2026-01-17 12:01:53,105 - INFO - Iter 10/10 | Loss: 23077.222656 | LR: 1.00e-05 | Speed: 0.94 it/s | ETA: 0.0min\r\n",
      "2026-01-17 12:01:53,507 - INFO - Saved checkpoint: /kaggle/working/output/stage1/fold_3/checkpoints/fold_3/final_model.pth\r\n",
      "2026-01-17 12:01:53,507 - INFO - Training completed!\r\n",
      "2026-01-17 12:01:58,516 - INFO -   Stage 1 checkpoint: /kaggle/working/output/stage1/fold_3/checkpoints/fold_3/final_model.pth\r\n",
      "2026-01-17 12:01:58,516 - INFO -   Training Stage 2 (Fold 3)...\r\n",
      "[DEBUG] Elastic deformation: num_control_points=5, max_displacement=5.0\r\n",
      "2026-01-17 12:01:59,143 - INFO - Multi-GPU training enabled: Using 2 GPUs [0, 1]\r\n",
      "2026-01-17 12:01:59,198 - INFO - Model wrapped with DataParallel on GPUs: [0, 1]\r\n",
      "2026-01-17 12:01:59,199 - INFO - Using provided model with 50,598,770 parameters\r\n",
      "2026-01-17 12:01:59,200 - INFO - Train samples: 113, Val samples: 28\r\n",
      "2026-01-17 12:01:59,201 - INFO - TensorBoard logs: /kaggle/working/output/stage2/fold_3/logs/fold_3\r\n",
      "2026-01-17 12:01:59,201 - INFO - Starting vertebrae localization training...\r\n",
      "2026-01-17 12:02:10,350 - INFO - Iter 1/10 | Loss: 739129.500000 | Sigma: [4.00, 4.00] | Speed: 0.18 it/s | ETA: 0.8min\r\n",
      "2026-01-17 12:03:03,854 - INFO - Iter 10/10 | Loss: 321294.312500 | Sigma: [4.00, 4.00] | Speed: 0.17 it/s | ETA: 0.0min\r\n",
      "2026-01-17 12:03:04,694 - INFO - Saved checkpoint: /kaggle/working/output/stage2/fold_3/checkpoints/fold_3/final_model.pth\r\n",
      "2026-01-17 12:03:04,694 - INFO - Training completed!\r\n",
      "2026-01-17 12:03:04,758 - INFO -   Stage 2 checkpoint: /kaggle/working/output/stage2/fold_3/checkpoints/fold_3/final_model.pth\r\n",
      "2026-01-17 12:03:04,758 - INFO -   Training Stage 3 (Fold 3)...\r\n",
      "[VertebraeSegmentationDataset] Warning: 17 IDs have no valid landmarks: ['sub-verse406', 'sub-verse416', 'sub-verse410', 'sub-verse405', 'sub-verse403']...\r\n",
      "[VertebraeSegmentationDataset] Warning: 1 IDs have no valid landmarks: ['sub-verse402']\r\n",
      "2026-01-17 12:03:05,021 - INFO -   Stage 3 datasets - Train: 952 vertebra samples, Val: 289 vertebra samples\r\n",
      "2026-01-17 12:03:05,022 - INFO - Multi-GPU training enabled: Using 2 GPUs [0, 1]\r\n",
      "2026-01-17 12:03:05,044 - INFO - Model wrapped with DataParallel on GPUs: [0, 1]\r\n",
      "2026-01-17 12:03:05,044 - INFO - Using provided model with 21,193,627 parameters\r\n",
      "2026-01-17 12:03:05,045 - INFO - Train samples: 952, Val samples: 289\r\n",
      "2026-01-17 12:03:05,046 - INFO - TensorBoard logs: /kaggle/working/output/stage3/fold_3/logs/fold_3\r\n",
      "2026-01-17 12:03:05,046 - INFO - Starting vertebrae segmentation training...\r\n",
      "2026-01-17 12:03:11,730 - INFO - Iter 1/10 | Loss: 3.692361 | Speed: 0.23 it/s | ETA: 0.6min\r\n",
      "2026-01-17 12:03:16,411 - ERROR - Error in fold 3: Caught FileNotFoundError in DataLoader worker process 0.\r\n",
      "Original Traceback (most recent call last):\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\r\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\r\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n",
      "            ~~~~~~~~~~~~^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/data/dataset.py\", line 1093, in __getitem__\r\n",
      "    image_path, label_path = self._get_paths(image_id)\r\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/data/dataset.py\", line 1083, in _get_paths\r\n",
      "    raise FileNotFoundError(f\"Image not found for ID: {image_id}\")\r\n",
      "FileNotFoundError: Image not found for ID: sub-verse108\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/train_kfold.py\", line 542, in main\r\n",
      "    ckpt3 = train_fold_stage3(\r\n",
      "            ^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/train_kfold.py\", line 291, in train_fold_stage3\r\n",
      "    trainer.train()\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/training/trainer.py\", line 954, in train\r\n",
      "    batch = next(train_iter)\r\n",
      "            ^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 734, in __next__\r\n",
      "    data = self._next_data()\r\n",
      "           ^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1516, in _next_data\r\n",
      "    return self._process_data(data, worker_id)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1551, in _process_data\r\n",
      "    data.reraise()\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/_utils.py\", line 769, in reraise\r\n",
      "    raise exception\r\n",
      "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.\r\n",
      "Original Traceback (most recent call last):\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\r\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\r\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n",
      "            ~~~~~~~~~~~~^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/data/dataset.py\", line 1093, in __getitem__\r\n",
      "    image_path, label_path = self._get_paths(image_id)\r\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/data/dataset.py\", line 1083, in _get_paths\r\n",
      "    raise FileNotFoundError(f\"Image not found for ID: {image_id}\")\r\n",
      "FileNotFoundError: Image not found for ID: sub-verse108\r\n",
      "\r\n",
      "2026-01-17 12:03:16,413 - INFO - \r\n",
      "2026-01-17 12:03:16,413 - INFO - ======================================================================\r\n",
      "2026-01-17 12:03:16,413 - INFO - FOLD 5/5\r\n",
      "2026-01-17 12:03:16,413 - INFO -   Train: 113 samples, Val: 28 samples\r\n",
      "2026-01-17 12:03:16,413 - INFO - ======================================================================\r\n",
      "2026-01-17 12:03:16,413 - INFO -   Training Stage 1 (Fold 4)...\r\n",
      "2026-01-17 12:03:20,672 - INFO - Multi-GPU training enabled: Using 2 GPUs [0, 1]\r\n",
      "2026-01-17 12:03:20,694 - INFO - Model wrapped with DataParallel on GPUs: [0, 1]\r\n",
      "2026-01-17 12:03:20,694 - INFO - Using provided model with 21,191,937 parameters\r\n",
      "2026-01-17 12:03:20,695 - INFO - Train samples: 113, Val samples: 28\r\n",
      "2026-01-17 12:03:20,696 - INFO - TensorBoard logs: /kaggle/working/output/stage1/fold_4/logs/fold_4\r\n",
      "2026-01-17 12:03:20,696 - INFO - Starting spine localization training...\r\n",
      "2026-01-17 12:03:29,599 - INFO - Iter 1/10 | Loss: 105201.632812 | LR: 7.94e-05 | Speed: 0.13 it/s | ETA: 1.2min\r\n",
      "2026-01-17 12:03:40,346 - ERROR - Error in fold 4: Caught FileNotFoundError in DataLoader worker process 1.\r\n",
      "Original Traceback (most recent call last):\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\r\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\r\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n",
      "            ~~~~~~~~~~~~^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/data/dataset.py\", line 529, in __getitem__\r\n",
      "    image_path = self._get_image_path(image_id)\r\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/data/dataset.py\", line 523, in _get_image_path\r\n",
      "    raise FileNotFoundError(f\"Image not found for ID: {image_id}\")\r\n",
      "FileNotFoundError: Image not found for ID: sub-verse236\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/train_kfold.py\", line 526, in main\r\n",
      "    ckpt1 = train_fold_stage1(\r\n",
      "            ^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/train_kfold.py\", line 152, in train_fold_stage1\r\n",
      "    trainer.train()\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/training/trainer.py\", line 363, in train\r\n",
      "    batch = next(train_iter)\r\n",
      "            ^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 734, in __next__\r\n",
      "    data = self._next_data()\r\n",
      "           ^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1489, in _next_data\r\n",
      "    return self._process_data(data, worker_id)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1551, in _process_data\r\n",
      "    data.reraise()\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/_utils.py\", line 769, in reraise\r\n",
      "    raise exception\r\n",
      "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 1.\r\n",
      "Original Traceback (most recent call last):\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\r\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\r\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\r\n",
      "            ~~~~~~~~~~~~^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/data/dataset.py\", line 529, in __getitem__\r\n",
      "    image_path = self._get_image_path(image_id)\r\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/SpineSegmentation_HealthiVert/src/data/dataset.py\", line 523, in _get_image_path\r\n",
      "    raise FileNotFoundError(f\"Image not found for ID: {image_id}\")\r\n",
      "FileNotFoundError: Image not found for ID: sub-verse236\r\n",
      "\r\n",
      "2026-01-17 12:03:40,348 - INFO - \r\n",
      "2026-01-17 12:03:40,348 - INFO - ======================================================================\r\n",
      "2026-01-17 12:03:40,348 - INFO - TRAINING COMPLETE\r\n",
      "2026-01-17 12:03:40,348 - INFO - ======================================================================\r\n",
      "2026-01-17 12:03:40,348 - INFO - \r\n",
      "STAGE1 Results:\r\n",
      "2026-01-17 12:03:40,348 - INFO -   Fold 0: /kaggle/working/output/stage1/fold_0/checkpoints/fold_0/final_model.pth\r\n",
      "2026-01-17 12:03:40,348 - INFO -   Fold 2: /kaggle/working/output/stage1/fold_2/checkpoints/fold_2/final_model.pth\r\n",
      "2026-01-17 12:03:40,349 - INFO -   Fold 3: /kaggle/working/output/stage1/fold_3/checkpoints/fold_3/final_model.pth\r\n",
      "2026-01-17 12:03:40,349 - INFO - \r\n",
      "STAGE2 Results:\r\n",
      "2026-01-17 12:03:40,349 - INFO -   Fold 0: /kaggle/working/output/stage2/fold_0/checkpoints/fold_0/final_model.pth\r\n",
      "2026-01-17 12:03:40,349 - INFO -   Fold 2: /kaggle/working/output/stage2/fold_2/checkpoints/fold_2/final_model.pth\r\n",
      "2026-01-17 12:03:40,349 - INFO -   Fold 3: /kaggle/working/output/stage2/fold_3/checkpoints/fold_3/final_model.pth\r\n",
      "2026-01-17 12:03:40,349 - INFO - \r\n",
      "Summary saved to: /kaggle/working/output/verse2019_kfold_summary.txt\r\n",
      "2026-01-17 12:03:40,349 - INFO - \r\n",
      "Done!\r\n"
     ]
    }
   ],
   "source": [
    "!cd SpineSegmentation_HealthiVert/ && python train_kfold.py \\\n",
    "    --data_dir /kaggle/input/verse-19-3d-images \\\n",
    "    --output_dir /kaggle/working/output \\\n",
    "    --splits_dir . \\\n",
    "    --stage all \\\n",
    "    --n_folds 5 \\\n",
    "    --iterations 10 \\\n",
    "    --batch_size 2 \\\n",
    "    --multi_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b59fddc",
   "metadata": {
    "papermill": {
     "duration": 0.006165,
     "end_time": "2026-01-17T12:03:44.812893",
     "exception": false,
     "start_time": "2026-01-17T12:03:44.806728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7f7a2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T12:03:44.826997Z",
     "iopub.status.busy": "2026-01-17T12:03:44.826406Z",
     "iopub.status.idle": "2026-01-17T12:03:48.939638Z",
     "shell.execute_reply": "2026-01-17T12:03:48.938574Z"
    },
    "papermill": {
     "duration": 4.122613,
     "end_time": "2026-01-17T12:03:48.941491",
     "exception": false,
     "start_time": "2026-01-17T12:03:44.818878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\r\n",
      "Warning: No val.txt found. Please specify validation IDs.\r\n"
     ]
    }
   ],
   "source": [
    "!cd /kaggle/working/SpineSegmentation_HealthiVert && python evaluate.py \\\n",
    "    --data_dir /kaggle/input/verse-19-3d-images \\\n",
    "    --output_dir /kaggle/working/output \\\n",
    "    --splits_dir . \\\n",
    "    --n_folds 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da6f2875",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T12:03:48.955586Z",
     "iopub.status.busy": "2026-01-17T12:03:48.955203Z",
     "iopub.status.idle": "2026-01-17T12:03:48.959262Z",
     "shell.execute_reply": "2026-01-17T12:03:48.958643Z"
    },
    "papermill": {
     "duration": 0.012883,
     "end_time": "2026-01-17T12:03:48.960660",
     "exception": false,
     "start_time": "2026-01-17T12:03:48.947777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cd /kaggle/working/SpineSegmentation_HealthiVert && python run_inference.py \\\n",
    "#   --input /kaggle/working/verse19/dataset-verse19test/rawdata/sub-verse012/sub-verse012_ct.nii.gz \\\n",
    "#   --output /kaggle/working/verse19/inference_output \\\n",
    "#   --stage all \\\n",
    "#   --stage1_ckpt /kaggle/working/verse19/output/stage1/fold_0/checkpoints/fold_0/final_model.pth \\\n",
    "#   --stage2_ckpt /kaggle/working/verse19/output/stage2/fold_0/checkpoints/fold_0/final_model.pth \\\n",
    "#   --stage3_ckpt /kaggle/working/verse19/output/stage3/fold_0/checkpoints/fold_0/final_model.pth"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6454328,
     "sourceId": 10414190,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 401.409483,
   "end_time": "2026-01-17T12:03:49.284803",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-17T11:57:07.875320",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
